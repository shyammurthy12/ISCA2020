\section{Background and Related Work}
Side channel is an unintentional leakage of information from a victim to an adversary because of the implementation of the hardware and the way of usage \cite{szefer2019survey}. Software guarantees isolation of the data, but the side channels bypass these guarantess and leak data. Cache based side channel attacks leak information about which addresses are referenced and in what order. When secrets are used to index into a data structure, it has the potential to leak information about the secret. This is common in a lot of implementations of cryptographic algorithms, where we have table lookups, for which the index comes from certain bits of the key. Examples of the same are multiplier tables in the RSA algorithm, which is implemented as a lookup table, for which the index comes from bits of the key \cite{liu2014random}.

Cache based side channel attacks can be broadly classified into \textit{conflict based attacks} \cite{deng2019analysis} and \textit{reuse based attacks}.

Conflict based attacks happen when the attacker and victim contend for the same cache set. The attacker exploits the deterministic nature of the mapping from addresses to sets, to learn information about the victim's address. Classic example of this kind of an attack is the Prime and Probe \cite{percival2005cache} \cite{osvik2006cache}. Here, the attacker first primes or fills one or more sets of the cache with his data. Then the attacker waits for the victim to run, and subsequently accesses the items to see if all the items are still cached. If any of the items see a longer access time, then the attacker knows which of his data items got evicted by the victim, and thereby learns information about the set in the cache, that saw contention from the victim. Our work seeks to mitigate these kinds of attacks, where the attack relies on learning the location of a memory line in the cache. 
Prior solutions to mitigate conflict based attacks in the L1 cache such as RPCache \cite{wang2007new} and NewCache \cite{wang2008novel} require large table lookups, and also require making changes to the address decoder logic within the cache to tolerate the additional latency introduced, which our scheme avoids. CEASER \cite{qureshi2018ceaser} uses an encrypted line address to index the cache, whereas application of a similar solution in the L1 cache is expensive, because the L1 cache access is on the critical path. <Given they perform an explicit remap after some time interval, you mention that it affects the quiescient state of the cache, could you help us elaborate> Other approaches such as way partitioning (static or dynamic) that seek to partition the ways of a cache across different protection domains \cite{wang2016secdcp} \cite{liu2016catalyst} \cite{domnitser2012non} \cite{kiriansky2018dawg} lead to under-utilization of cache space and become less feasible in the context of an L1 cache, where space is more of a premium. PLCache \cite{wang2007new} requires locking of certain cache lines, which again leads to under-utilization of cache space.

Reuse Based attacks in contrast do not rely on the location of the memory line in the cache and instead only rely on the fact that a line that was accessed previoiusly will be cached and a subsequent reference would result in a cache hit. These attacks are possible when there is data that is shared between the attacker and the victim. An example of such an attack is the Flush+Reload attack \cite{yarom2014flush+}. Here, the attacker can directly access the target addresses (unlike in the case of conflict based attack, where the attacker was using conflicting addresses to launch the attack), for example if the target addresses are a part of a shared library. The attacker has to run \textit{clflush} \cite{guide2016intel} instruction, to flush all the target addresses from the cache. This gives a guarantee that the addresses have indeed been written back to memory and invalidated in the caches. Then, the attacker lets the victim run, and subsequently measures the time to access each of the target lines he had flushed. If any of the target addresses hit in the cache, it would have a lower access time, giving the attacker information about the address that was accessed.   
